<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration  xmlns:xi="http://www.w3.org/2001/XInclude">
   <xi:include href="hdfs-site.private.xml"/>
   <property>
    <name>dfs.nameservices</name>
    <value>{{hdfs__nameservice_id}}</value>
  </property>
  <property>
   <name>dfs.ha.namenodes.{{hdfs__nameservice_id}}</name>
   <value>{{hdfs__namenode1}},{{hdfs__namenode2}}</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>{{hdfs__dfs_blocksize}}</value>
  </property>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>{{hdfs__dfs_permissions_superusergroup}}</value>
  </property>
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>ha.zookeeper.quorum</name>
    <value>{{groups.ZOOKEEPER | join(':' ~ zookeeper__zookeeper_client_port + ',')}}:{{zookeeper__zookeeper_client_port}}</value>
  </property>
  <!-- for namenode1 -->
  <property>
    <name>dfs.namenode.rpc-address.{{hdfs__nameservice_id}}.{{hdfs__namenode1}}</name>
    <value>{{groups['NAMENODE'][0]}}:{{hdfs__dfs_namenode_rpc_address_port}}</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.{{hdfs__nameservice_id}}.{{hdfs__namenode1}}</name>
    <value>{{groups['NAMENODE'][0]}}:{{hdfs__dfs_namenode_http_address_port}}</value>
  </property>
  <property>
    <name>dfs.namenode.https-address.{{hdfs__nameservice_id}}.{{hdfs__namenode1}}</name>
    <value>{{groups['NAMENODE'][0]}}:{{hdfs__dfs_namenode_https_address_port}}</value>
  </property>
  <!-- for namenode2 -->
  <property>
    <name>dfs.namenode.rpc-address.{{hdfs__nameservice_id}}.{{hdfs__namenode2}}</name>
    <value>{{groups['NAMENODE'][1]}}:{{hdfs__dfs_namenode_rpc_address_port}}</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.{{hdfs__nameservice_id}}.{{hdfs__namenode2}}</name>
    <value>{{groups['NAMENODE'][1]}}:{{hdfs__dfs_namenode_http_address_port}}</value>
  </property>
  <property>
    <name>dfs.namenode.https-address.{{hdfs__nameservice_id}}.{{hdfs__namenode2}}</name>
    <value>{{groups['NAMENODE'][1]}}:{{hdfs__dfs_namenode_https_address_port}}</value>
  </property>

  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://{{groups.QJM | join(':' ~ hdfs__qjournal_port + ';')}}:{{hdfs__qjournal_port}}/{{hdfs__dfs_namenode_shared_edits_dir}}</value>
  </property>
  <property>
   <name>dfs.journalnode.edits.dir</name>
   <value>{{hdfs__dfs_journalnode_edits_dir}}</value>
  </property>  
  <property>
    <name>dfs.namenode.edits.journal-plugin.qjournal</name>
    <value>org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</value>
  </property>
  <property>
    <name>dfs.journalnode.rpc-address</name>
    <value>0.0.0.0:{{hdfs__qjournal_port}}</value>
  </property>
  <property>
    <name>dfs.journalnode.http-address</name>
    <value>0.0.0.0:{{hdfs__qjournal_http_port}}</value>
  </property>
  <property>
   <name>dfs.client.failover.proxy.provider.{{hdfs__nameservice_id}}</name>
   <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
 <property>
   <name>dfs.ha.fencing.methods</name>
   <value>{{hdfs__dfs_ha_fencing_methods}}</value>
 </property>
 <property>
   <name>dfs.ha.fencing.ssh.private-key-files</name>
   <value>{{hdfs__dfs_ha_fencing_ssh_private_key_files}}</value>
 </property>

 <property>
    <name>dfs.namenode.support.allow.format</name>
    <value>{{hdfs__dfs_namenode_support_allow_format}}</value>
 </property>
  
 <property>
    <name>dfs.ha.zkfc.port</name>
    <value>{{hdfs__dfs_ha_zkfc_port}}</value>
  </property>
  
 <property>
    <name>dfs.datanode.address</name>
    <value>0.0.0.0:{{hdfs__dfs_datanode_address_port}}</value>
  </property>
  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:{{hdfs__dfs_datanode_http_address_port}}</value>
  </property>
  <property>
    <name>dfs.datanode.ipc.address</name>
    <value>0.0.0.0:{{hdfs__dfs_datanode_ipc_address_port}}</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>{{hdfs__dfs_replication}}</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>{{hdfs__dfs_namenode_name_dir | join(',')}}</value>
  </property>
  <property>
    <name>dfs.hosts</name>
    <value>{{hadoop_conf_dir}}/dfs_hosts_include.txt</value>
  </property>
  <property>
    <name>dfs.hosts.exclude</name>
    <value>{{hadoop_conf_dir}}/dfs_hosts_exclude.txt</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.txns</name>
    <value>1000000</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.period</name>
    <value>3600</value>
  </property>
  <property>
    <name>dfs.namenode.replication.min</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.replication.max</name>
    <value>40</value>
  </property>
  <property>
    <name>dfs.namenode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>256</value>
  </property>
  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>256</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir.restore</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.thrift.threads.max</name>
    <value>20</value>
  </property>
  <property>
    <name>dfs.thrift.threads.min</name>
    <value>10</value>
  </property>
  <property>
    <name>dfs.thrift.timeout</name>
    <value>60</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.threshold-pct</name>
    <value>0.999</value>
  </property>
  <property>
    <name>dfs.namenode.invalidate.work.pct.per.iteration</name>
    <value>0.32</value>
  </property>
  <property>
    <name>dfs.namenode.replication.work.multiplier.per.iteration</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.safemode.min.datanodes</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.extension</name>
    <value>30000</value>
  </property>
  <property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>false</value>
  </property>
  <property>
    <name>fs.permissions.umask-mode</name>
    <value>{{hdfs__fs_permissions_umask_mode}}</value>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer.algorithm</name>
    <value>rc4</value>
  </property>
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.datanode.drop.cache.behind.writes</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.datanode.drop.cache.behind.reads</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.sync.behind.writes</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.datanode.readahead.bytes</name>
    <value>8388608</value>
  </property>
  <property>
    <name>dfs.datanode.fsdataset.volume.choosing.policy</name>
    <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy</value>
  </property>
<property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>755</value>
  </property>
  <property>
    <name>dfs.datanode.handler.count</name>
    <value>64</value>
  </property>
  <property>
    <name>dfs.datanode.max.transfer.threads</name>
    <value>5120</value>
  </property>
  <property>
    <name>dfs.datanode.du.reserved</name>
    <value>{{hdfs__dfs_datanode_du_reserved}}</value>
  </property>
  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>{{hdfs__dfs_datanode_failed_volumes_tolerated}}</value>
  </property>
  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>31457280</value>
  </property>
  <property>
    <name>dfs.datanode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.block.local-path-access.user</name>
    <value>impala,kpi</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.domain.socket.path</name>
    <value>{{ hdfs__dfs_domain_socket_path }}</value>
  </property>
  <property>
    <name>dfs.client.file-block-storage-locations.timeout</name>
    <value>3000</value>
  </property>
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit.skip.checksum</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.domain.socket.data.traffic</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.socket-timeout</name>
    <value>180000</value>
  </property>
  <property>
    <name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
    <value>ALWAYS</value>
  </property>

</configuration>
